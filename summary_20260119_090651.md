---
layout: default
title: 2026-01-19 ArXiv 摘要
---

# Arxiv LLM 每日研报

> **更新时间**：2026-01-19 17:08:08
> **论文数量**：8 篇
> **推荐分布**：⭐推荐 3 篇 \| 📌边缘可看 3 篇 \| ❌不推荐 2 篇
> **自动生成**：By Arxiv\_LLM\_Daily Agent

---

## 📊 今日趋势速览 (Trend Analysis)


<div style='display: flex; justify-content: space-around; align-items: flex-start; flex-wrap: wrap; gap: 20px; margin: 20px 0;'>

<div style='flex: 1; min-width: 300px; text-align: center;'>
<h4 style='margin-bottom: 10px;'>研究热点分布</h4>
<img src='img/summary\_20260119\_090651\_trend\_pie.png' alt='研究热点分布' style='max-width: 100%; height: auto;' />
</div>

<div style='flex: 1; min-width: 300px; text-align: center;'>
<h4 style='margin-bottom: 10px;'>关键词分布（Top 8）</h4>
<img src='img/summary\_20260119\_090651\_keywords\_pie.png' alt='关键词分布' style='max-width: 100%; height: auto;' />
</div>

</div>

### <span style='display: inline-block; width: 12px; height: 12px; border-radius: 50%; background-color: #8dd3c7; margin-right: 6px; vertical-align: middle;'></span> 小样本视觉模型优化（对应最大聚类，3 篇论文）
> **赛道观察：** 极少量标注数据下CNN架构仍显著优于Transformer，遥感领域的小样本训练技术成为焦点
- Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images

### <span style='display: inline-block; width: 12px; height: 12px; border-radius: 50%; background-color: #80b1d3; margin-right: 6px; vertical-align: middle;'></span> 社会科学LLM选型方法论（对应第二大聚类，2 篇论文）
> **赛道观察：** 强调小型开放模型的可复现性优势，建立任务特定验证流程替代通用基准测试
- Selecting Language Models for Social Science: Start Small, Start Open, and Validate

### <span style='display: inline-block; width: 12px; height: 12px; border-radius: 50%; background-color: #d9d9d9; margin-right: 6px; vertical-align: middle;'></span> 边缘计算训练优化（对应第三大聚类，2 篇论文）
> **赛道观察：** 混合阶优化策略成为突破点，零阶客户端+一阶服务器实现内存-性能平衡
- HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training

### <span style='display: inline-block; width: 12px; height: 12px; border-radius: 50%; background-color: #ffed6f; margin-right: 6px; vertical-align: middle;'></span> RAG安全防御（对应第四大聚类，1 篇论文）
> **赛道观察：** 社交网络场景的隐蔽攻击载体标准化测试需求激增，HTML净化与Unicode处理成关键防御手段
- Hidden-in-Plain-Text: A Benchmark for Social-Web Indirect Prompt Injection in RAG

---

## 📝 论文详细列表

## 1. ⭐ Hidden-in-Plain-Text: A Benchmark for Social-Web Indirect Prompt Injection in RAG
- **中文标题**: 隐藏的间接提示注入基准：面向社交网络RAG系统的评估框架
- **Link**: http://arxiv.org/abs/2601.10923v1
- **推荐决策:** 推荐
- **决策理由:** 命中LLM+RAG方向，提出的安全测试框架具有明确的工程实现路径，可直接应用于金融客服、风控等场景的RAG系统加固
- **关键词:** RAG安全、间接提示注入、检索中毒、多模态防御、社交网络数据
- **核心痛点:** 现有RAG系统缺乏对社交网络内容中隐蔽攻击载体的标准化测试方法
- **应用价值:** 为金融领域RAG系统提供可落地的安全测试方案，防范来自社交媒体的数据污染风险
- **总结:** OpenRAG-Soc提出了首个针对社交网络场景的RAG安全基准，系统评估了间接提示注入和检索中毒攻击，并验证了三种可部署防御措施的有效性。该框架特别关注实际业务中常见的HTML/无障碍/Unicode攻击载体。
- **技术创新:** 1) 构建包含6,200个社交网络页面的测试语料库，覆盖5种攻击载体；2) 设计可组合的防御策略（HTML净化、Unicode标准化、属性门控）；3) 开发端到端评估管道，量化攻击成功率(ASR)和检索排名变化(ΔMRR)；4) 在BM25和稠密检索器上验证防御效果，最佳配置将ASR从24.9%降至4.7%


---

## 2. ⭐ HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training
- **中文标题**: HOSL：面向内存受限边缘训练的混合阶分步学习
- **Link**: http://arxiv.org/abs/2601.10940v1
- **推荐决策:** 推荐
- **决策理由:** 命中LLM工程化方向，提出的方法具有明确的实现路径和实际应用价值，可迁移到金融领域的边缘计算场景
- **关键词:** 分步学习、边缘计算、LLM训练优化
- **核心痛点:** 现有分步学习系统在内存效率和优化效果之间存在根本性权衡
- **应用价值:** 在资源受限的边缘设备上高效训练大型语言模型，降低内存开销
- **总结:** HOSL提出了一种混合阶分步学习框架，通过在客户端使用零阶优化减少内存消耗，同时在服务器端使用一阶优化保证性能，实现了内存效率和训练效果的平衡。
- **技术创新:** 1) 客户端采用零阶优化减少内存使用；2) 服务器端采用一阶优化保证收敛速度；3) 理论证明收敛率仅依赖客户端模型维度；4) 在OPT模型上实验显示内存减少3.7倍，精度损失控制在0.20%-4.23%


---

## 3. ⭐ SwiftKV: An Edge-Oriented Attention Algorithm and Multi-Head Accelerator for Fast, Efficient LLM Decoding
- **中文标题**: SwiftKV：面向边缘的快速高效LLM解码注意力算法与多头加速器
- **Link**: http://arxiv.org/abs/2601.10953v1
- **推荐决策:** 推荐
- **决策理由:** 直接命中LLM工程化方向，提出的硬件加速方案具有明确的金融场景应用潜力，如实时金融数据分析和服务
- **关键词:** 边缘计算、注意力优化、LLM加速
- **核心痛点:** 现有边缘加速器在资源受限环境下难以实现快速注意力推理和高效解码
- **应用价值:** 在边缘设备上实现高效的大型语言模型推理，提升响应速度和能效
- **总结:** SwiftKV提出了一种面向边缘的注意力算法和加速器设计，显著降低了LLM解码的延迟和资源消耗，为边缘设备上的高效推理提供了解决方案。
- **技术创新:** 1) 提出SwiftKV注意力算法，实现单次处理KV缓存；2) 设计SwiftKV-MHA加速器支持多头并行解码；3) 实验显示注意力延迟降低13.48倍，生成速度提升17.4%；4) 在FPGA上实现1100.3 GOPS的吞吐量


---

## 4. Massively Multilingual Joint Segmentation and Glossing
- **中文标题**: 大规模多语言联合分词与词义标注
- **Link**: http://arxiv.org/abs/2601.10925v1
- **推荐决策:** 边缘可看
- **决策理由:** 虽然多语言处理技术有一定通用性，但与金融核心业务关联较弱，仅在特定跨境场景可能有潜在应用价值
- **关键词:** 多语言处理、词义标注、形态分割、低资源语言、序列到序列模型
- **核心痛点:** 现有词义标注模型无法同时预测形态分割边界，导致输出缺乏可解释性
- **应用价值:** 提升低资源语言处理能力，为跨境金融服务的多语言文本分析提供技术支持
- **总结:** 该研究首次实现了神经模型对原始文本的联合形态分割和词义标注，通过多语言序列到序列架构和创新的训练策略，解决了传统方法输出不可信的问题，特别适用于低资源语言场景。
- **技术创新:** 1) 扩展GlossLM训练语料构建PolyGloss模型家族；2) 设计联合训练目标平衡分割与标注准确率；3) 采用低秩适应(LoRA)实现新语言的快速适配；4) 在多种濒危语言上超越单任务基线模型


---

## 5. Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images
- **中文标题**: 稀疏数据树冠分割：仅用150张图像微调领先预训练模型
- **Link**: http://arxiv.org/abs/2601.10931v1
- **推荐决策:** 边缘可看
- **决策理由:** 小样本学习技术有一定通用性，但论文聚焦生态遥感场景，与金融应用关联度较低，需显著改造才能应用于金融图像分析
- **关键词:** 小样本学习、遥感图像、实例分割、模型比较、数据增强
- **核心痛点:** 遥感图像标注稀缺导致深度学习模型容易过拟合
- **应用价值:** 为金融领域的卫星图像分析（如绿色信贷评估）提供小样本学习方法参考
- **总结:** 该研究通过严格的对照实验证明，在极少量标注数据(150张)条件下，基于CNN的实例分割模型显著优于transformer架构，为遥感图像的小样本分析提供了实用指南。
- **技术创新:** 1) 在150张航空图像上系统比较5种架构(YOLOv11/Mask R-CNN/DeepLabv3/Swin-UNet/DINOv2)；2) 验证CNN模型在mAP指标上的显著优势(YOLOv11达0.281)；3) 分析transformer模型在小数据下的过拟合问题；4) 提供针对极少量数据的增强策略和训练技巧


---

## 6. Can Instructed Retrieval Models Really Support Exploration?
- **中文标题**: 指令检索模型真的支持探索吗？
- **Link**: http://arxiv.org/abs/2601.10936v1
- **推荐决策:** 边缘可看
- **决策理由:** 虽然涉及LLM的应用，但主要关注信息检索领域，与金融场景的直接关联较弱，迁移成本较高
- **关键词:** 指令检索、探索性搜索、LLM评测
- **核心痛点:** 现有指令检索模型在探索性搜索中对指令的敏感性和适应性不足
- **应用价值:** 提升探索性搜索系统的用户体验，特别是在科学文献检索等场景中
- **总结:** 该论文评估了指令检索模型在探索性搜索中的应用，发现虽然这些模型在排名相关性上有所改进，但在指令跟随和敏感性方面表现不佳，限制了其在长期探索性会话中的实用性。
- **技术创新:** 1) 使用专家标注的数据集CSFCube评估指令检索模型；2) 比较微调的LLM和通用LLM在指令检索中的表现；3) 评估模型在排名相关性和指令跟随能力上的差异；4) 实验结果显示最佳指令检索模型在排名相关性上优于无指令模型，但在指令跟随上表现不一致


---

## 7. Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images
- **中文标题**: 自学习表示引导的潜在扩散模型用于深紫外全表面图像中的乳腺癌分类
- **Link**: http://arxiv.org/abs/2601.10917v1
- **推荐决策:** 不推荐
- **决策理由:** 虽然技术新颖，但应用场景完全聚焦于医学影像分析，与金融领域无直接关联，且迁移成本极高
- **关键词:** 潜在扩散模型、自监督学习、医学图像合成、乳腺癌分类、多模态融合
- **核心痛点:** 医学图像标注数据稀缺导致深度学习模型训练困难
- **应用价值:** 通过合成数据增强医学图像分析模型的训练数据，提高乳腺癌手术中的边缘评估准确性
- **总结:** 该研究提出了一种结合自监督学习和潜在扩散模型的方法，用于生成高质量的合成医学图像数据以解决数据稀缺问题。通过DINO模型提取的语义嵌入指导LDM生成具有细粒度细胞结构的合成图像，显著提升了乳腺癌分类模型的性能。
- **技术创新:** 1) 使用微调DINO教师模型提取SSL嵌入指导LDM生成合成图像；2) 在潜在空间进行扩散降低计算成本；3) 结合真实和合成数据微调Vision Transformer；4) 在5折交叉验证中达到96.47%准确率，FID分数降至45.72


---

## 8. Selecting Language Models for Social Science: Start Small, Start Open, and Validate
- **中文标题**: 社会科学中的语言模型选择：从小型开放模型开始并验证
- **Link**: http://arxiv.org/abs/2601.10926v1
- **推荐决策:** 不推荐
- **决策理由:** 聚焦社会科学研究方法论，虽涉及LLM但缺乏具体的工程实现或金融场景适配方案
- **关键词:** 模型选择、可复现性、开放模型、社会科学、LLM验证
- **核心痛点:** 社会科学研究缺乏针对LLM选择的系统性方法论
- **应用价值:** 为金融文本分析提供模型选型方法论，平衡性能与合规要求
- **总结:** 该论文系统分析了语言模型选择的考量因素，主张从小型开放模型入手并通过严格的管道验证来确保研究可靠性，对处理敏感金融数据时的模型选型具有参考价值。
- **技术创新:** 1) 提出四维评估框架：模型开放性、计算足迹、训练数据、架构与微调；2) 构建包含20+模型家族的比较矩阵；3) 强调小型开放模型在可复现性方面的优势；4) 推荐任务特定的验证流程而非依赖通用基准


---

---
*Generated by AI Agent based on arXiv (cs.CL)*
